{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaspere</th>\n",
       "      <th>ab</th>\n",
       "      <th>abated</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>accepted</th>\n",
       "      <th>accepting</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>...</th>\n",
       "      <th>worthiness</th>\n",
       "      <th>written</th>\n",
       "      <th>www</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yield</th>\n",
       "      <th>zakusala</th>\n",
       "      <th>üksnurme</th>\n",
       "      <th>ādaži</th>\n",
       "      <th>šperbergs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>merko2020_q1_en_eur_con_00.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q2_en_eur_con_00.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q3_en_eur_con_00.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q4_en_eur_con_00.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 2086 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                aaspere  ab  abated  able  abroad  accept  \\\n",
       "merko2020_q1_en_eur_con_00.txt        2   1       1     0       1       1   \n",
       "merko2020_q2_en_eur_con_00.txt        2   1       0     2       1       1   \n",
       "merko2020_q3_en_eur_con_00.txt        2   1       0     1       1       1   \n",
       "merko2020_q4_en_eur_con_00.txt        0   1       0     1       1       1   \n",
       "\n",
       "                                acceptance  accepted  accepting  \\\n",
       "merko2020_q1_en_eur_con_00.txt           1         1          0   \n",
       "merko2020_q2_en_eur_con_00.txt           1         1          1   \n",
       "merko2020_q3_en_eur_con_00.txt           1         1          0   \n",
       "merko2020_q4_en_eur_con_00.txt           1         1          0   \n",
       "\n",
       "                                accommodation  ...  worthiness  written  www  \\\n",
       "merko2020_q1_en_eur_con_00.txt              1  ...           0        0    3   \n",
       "merko2020_q2_en_eur_con_00.txt              0  ...           1        1    4   \n",
       "merko2020_q3_en_eur_con_00.txt              0  ...           0        1    0   \n",
       "merko2020_q4_en_eur_con_00.txt              0  ...           0        1    0   \n",
       "\n",
       "                                year  years  yield  zakusala  üksnurme  ādaži  \\\n",
       "merko2020_q1_en_eur_con_00.txt    17     17      2         1         1      0   \n",
       "merko2020_q2_en_eur_con_00.txt    33     11      2         1         1      0   \n",
       "merko2020_q3_en_eur_con_00.txt    19     15      2         1         0      2   \n",
       "merko2020_q4_en_eur_con_00.txt    30     17      3         1         0      4   \n",
       "\n",
       "                                šperbergs  \n",
       "merko2020_q1_en_eur_con_00.txt          2  \n",
       "merko2020_q2_en_eur_con_00.txt          1  \n",
       "merko2020_q3_en_eur_con_00.txt          1  \n",
       "merko2020_q4_en_eur_con_00.txt          1  \n",
       "\n",
       "[4 rows x 2086 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('pickles/merkodtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merko2020_q1_en_eur_con_00.txt</th>\n",
       "      <th>merko2020_q2_en_eur_con_00.txt</th>\n",
       "      <th>merko2020_q3_en_eur_con_00.txt</th>\n",
       "      <th>merko2020_q4_en_eur_con_00.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaspere</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abated</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abroad</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         merko2020_q1_en_eur_con_00.txt  merko2020_q2_en_eur_con_00.txt  \\\n",
       "aaspere                               2                               2   \n",
       "ab                                    1                               1   \n",
       "abated                                1                               0   \n",
       "able                                  0                               2   \n",
       "abroad                                1                               1   \n",
       "\n",
       "         merko2020_q3_en_eur_con_00.txt  merko2020_q4_en_eur_con_00.txt  \n",
       "aaspere                               2                               0  \n",
       "ab                                    1                               1  \n",
       "abated                                0                               0  \n",
       "able                                  1                               1  \n",
       "abroad                                1                               1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pickle.load(open(\"pickles/merkocv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"general\" + 0.002*\"lithuania\" + 0.002*\"net\" + 0.002*\"term\" + 0.002*\"dividends\" + 0.002*\"period\" + 0.002*\"joint\" + 0.002*\"financial\" + 0.002*\"apartments\" + 0.002*\"liabilities\"'),\n",
       " (1,\n",
       "  '0.006*\"apartments\" + 0.006*\"term\" + 0.006*\"dividends\" + 0.006*\"general\" + 0.006*\"shares\" + 0.006*\"related\" + 0.006*\"groups\" + 0.006*\"financial\" + 0.006*\"period\" + 0.005*\"euros\"')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"apartments\" + 0.006*\"term\" + 0.006*\"dividends\" + 0.006*\"general\" + 0.006*\"shares\" + 0.006*\"related\" + 0.006*\"groups\" + 0.006*\"financial\" + 0.006*\"period\" + 0.006*\"lithuania\"'),\n",
       " (1,\n",
       "  '0.001*\"general\" + 0.001*\"financial\" + 0.001*\"period\" + 0.001*\"term\" + 0.001*\"related\" + 0.001*\"lithuania\" + 0.001*\"projects\" + 0.001*\"dividends\" + 0.001*\"apartments\" + 0.001*\"members\"'),\n",
       " (2,\n",
       "  '0.002*\"net\" + 0.002*\"lithuania\" + 0.002*\"liabilities\" + 0.002*\"dividends\" + 0.002*\"related\" + 0.002*\"euros\" + 0.002*\"term\" + 0.002*\"shares\" + 0.002*\"apartments\" + 0.002*\"general\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"term\" + 0.001*\"lithuania\" + 0.001*\"financial\" + 0.001*\"period\" + 0.001*\"general\" + 0.001*\"groups\" + 0.001*\"related\" + 0.001*\"apartments\" + 0.001*\"euros\" + 0.001*\"latvia\"'),\n",
       " (1,\n",
       "  '0.007*\"apartments\" + 0.006*\"dividends\" + 0.006*\"term\" + 0.006*\"general\" + 0.006*\"shares\" + 0.006*\"related\" + 0.006*\"financial\" + 0.006*\"groups\" + 0.006*\"net\" + 0.006*\"period\"'),\n",
       " (2,\n",
       "  '0.001*\"general\" + 0.001*\"euros\" + 0.001*\"related\" + 0.001*\"dividends\" + 0.001*\"term\" + 0.001*\"shares\" + 0.001*\"members\" + 0.001*\"quarter\" + 0.001*\"groups\" + 0.001*\"net\"'),\n",
       " (3,\n",
       "  '0.009*\"march\" + 0.006*\"general\" + 0.006*\"period\" + 0.005*\"tallinn\" + 0.005*\"groups\" + 0.005*\"lithuania\" + 0.005*\"latvia\" + 0.005*\"financial\" + 0.005*\"shares\" + 0.005*\"term\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>merko2020_q1_en_eur_con_00.txt</th>\n",
       "      <td>as merko ehitus consolidated interim report as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q2_en_eur_con_00.txt</th>\n",
       "      <td>as merko ehitus consolidated interim report as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q3_en_eur_con_00.txt</th>\n",
       "      <td>as merko ehitus consolidated interim report as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q4_en_eur_con_00.txt</th>\n",
       "      <td>as merko ehitus consolidated interim report as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             text\n",
       "merko2020_q1_en_eur_con_00.txt  as merko ehitus consolidated interim report as...\n",
       "merko2020_q2_en_eur_con_00.txt  as merko ehitus consolidated interim report as...\n",
       "merko2020_q3_en_eur_con_00.txt  as merko ehitus consolidated interim report as...\n",
       "merko2020_q4_en_eur_con_00.txt  as merko ehitus consolidated interim report as..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data, before the CountVectorizer step\n",
    "data_clean = pd.read_pickle('pickles/merko.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>merko2020_q1_en_eur_con_00.txt</th>\n",
       "      <td>merko ehitus report ehitus group months report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q2_en_eur_con_00.txt</th>\n",
       "      <td>merko ehitus report ehitus group months quarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q3_en_eur_con_00.txt</th>\n",
       "      <td>merko ehitus report ehitus group months quarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q4_en_eur_con_00.txt</th>\n",
       "      <td>merko ehitus report ehitus group months quarte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             text\n",
       "merko2020_q1_en_eur_con_00.txt  merko ehitus report ehitus group months report...\n",
       "merko2020_q2_en_eur_con_00.txt  merko ehitus report ehitus group months quarte...\n",
       "merko2020_q3_en_eur_con_00.txt  merko ehitus report ehitus group months quarte...\n",
       "merko2020_q4_en_eur_con_00.txt  merko ehitus report ehitus group months quarte..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns = pd.DataFrame(data_clean.text.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceptance</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>accordance</th>\n",
       "      <th>account</th>\n",
       "      <th>accounting</th>\n",
       "      <th>accounts</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actions</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>worthiness</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yield</th>\n",
       "      <th>zakusala</th>\n",
       "      <th>üksnurme</th>\n",
       "      <th>ādaži</th>\n",
       "      <th>šperbergs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>merko2020_q1_en_eur_con_00.txt</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q2_en_eur_con_00.txt</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q3_en_eur_con_00.txt</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q4_en_eur_con_00.txt</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                acceptance  accommodation  accordance  \\\n",
       "merko2020_q1_en_eur_con_00.txt           1              1           5   \n",
       "merko2020_q2_en_eur_con_00.txt           1              0           5   \n",
       "merko2020_q3_en_eur_con_00.txt           1              0           6   \n",
       "merko2020_q4_en_eur_con_00.txt           1              0           6   \n",
       "\n",
       "                                account  accounting  accounts  acquisition  \\\n",
       "merko2020_q1_en_eur_con_00.txt        3           2         6            3   \n",
       "merko2020_q2_en_eur_con_00.txt        3           2         7            3   \n",
       "merko2020_q3_en_eur_con_00.txt        3           5         7            3   \n",
       "merko2020_q4_en_eur_con_00.txt        3           5         7            3   \n",
       "\n",
       "                                act  action  actions  ...  world  worth  \\\n",
       "merko2020_q1_en_eur_con_00.txt    1       3        3  ...      1      1   \n",
       "merko2020_q2_en_eur_con_00.txt    1       3        2  ...      3      2   \n",
       "merko2020_q3_en_eur_con_00.txt    1       3        2  ...      1      1   \n",
       "merko2020_q4_en_eur_con_00.txt    2       2        1  ...      0      2   \n",
       "\n",
       "                                worthiness  year  years  yield  zakusala  \\\n",
       "merko2020_q1_en_eur_con_00.txt           0    17     17      2         1   \n",
       "merko2020_q2_en_eur_con_00.txt           1    33     11      2         1   \n",
       "merko2020_q3_en_eur_con_00.txt           0    19     15      2         1   \n",
       "merko2020_q4_en_eur_con_00.txt           0    30     17      3         1   \n",
       "\n",
       "                                üksnurme  ādaži  šperbergs  \n",
       "merko2020_q1_en_eur_con_00.txt         1      0          2  \n",
       "merko2020_q2_en_eur_con_00.txt         1      0          1  \n",
       "merko2020_q3_en_eur_con_00.txt         0      2          1  \n",
       "merko2020_q4_en_eur_con_00.txt         0      4          1  \n",
       "\n",
       "[4 rows x 1145 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "add_stop_words = ['www','interim','report','statements','period','ab','abbr','yes','žvejų','žaneta','žilvista','živilė','šalys','šarūnas','žukauskas','žūb','įmonės','świnoujście','šiaulių']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.text)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"ehitus\" + 0.007*\"merko\" + 0.006*\"construction\" + 0.006*\"eur\" + 0.005*\"months\" + 0.005*\"board\" + 0.005*\"group\" + 0.004*\"management\" + 0.004*\"profit\" + 0.004*\"revenue\"'),\n",
       " (1,\n",
       "  '0.026*\"construction\" + 0.023*\"merko\" + 0.020*\"group\" + 0.020*\"ehitus\" + 0.020*\"eur\" + 0.018*\"management\" + 0.018*\"months\" + 0.017*\"board\" + 0.016*\"profit\" + 0.012*\"revenue\"')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.002*\"merko\" + 0.002*\"construction\" + 0.002*\"ehitus\" + 0.002*\"eur\" + 0.002*\"profit\" + 0.002*\"months\" + 0.002*\"management\" + 0.002*\"group\" + 0.002*\"revenue\" + 0.002*\"board\"'),\n",
       " (1,\n",
       "  '0.026*\"construction\" + 0.023*\"merko\" + 0.020*\"group\" + 0.020*\"ehitus\" + 0.020*\"eur\" + 0.018*\"management\" + 0.018*\"months\" + 0.017*\"board\" + 0.016*\"profit\" + 0.012*\"revenue\"'),\n",
       " (2,\n",
       "  '0.004*\"merko\" + 0.003*\"group\" + 0.003*\"management\" + 0.003*\"ehitus\" + 0.003*\"months\" + 0.002*\"construction\" + 0.002*\"profit\" + 0.002*\"board\" + 0.002*\"eur\" + 0.002*\"revenue\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try topics = 3\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.026*\"construction\" + 0.024*\"merko\" + 0.020*\"group\" + 0.020*\"ehitus\" + 0.020*\"eur\" + 0.018*\"management\" + 0.018*\"months\" + 0.017*\"board\" + 0.016*\"profit\" + 0.012*\"revenue\"'),\n",
       " (1,\n",
       "  '0.006*\"construction\" + 0.004*\"eur\" + 0.003*\"merko\" + 0.003*\"management\" + 0.003*\"profit\" + 0.003*\"ehitus\" + 0.003*\"board\" + 0.003*\"months\" + 0.003*\"group\" + 0.003*\"revenue\"'),\n",
       " (2,\n",
       "  '0.005*\"merko\" + 0.005*\"construction\" + 0.005*\"ehitus\" + 0.004*\"eur\" + 0.004*\"management\" + 0.004*\"board\" + 0.003*\"months\" + 0.003*\"group\" + 0.003*\"profit\" + 0.003*\"revenue\"'),\n",
       " (3,\n",
       "  '0.002*\"merko\" + 0.002*\"construction\" + 0.002*\"ehitus\" + 0.002*\"management\" + 0.002*\"group\" + 0.002*\"eur\" + 0.002*\"months\" + 0.002*\"tax\" + 0.002*\"board\" + 0.002*\"profit\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Let's try 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>merko2020_q1_en_eur_con_00.txt</th>\n",
       "      <td>merko ehitus interim report merko ehitus group...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q2_en_eur_con_00.txt</th>\n",
       "      <td>merko ehitus interim report merko ehitus group...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q3_en_eur_con_00.txt</th>\n",
       "      <td>merko ehitus interim report merko ehitus group...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q4_en_eur_con_00.txt</th>\n",
       "      <td>merko ehitus interim report merko ehitus group...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             text\n",
       "merko2020_q1_en_eur_con_00.txt  merko ehitus interim report merko ehitus group...\n",
       "merko2020_q2_en_eur_con_00.txt  merko ehitus interim report merko ehitus group...\n",
       "merko2020_q3_en_eur_con_00.txt  merko ehitus interim report merko ehitus group...\n",
       "merko2020_q4_en_eur_con_00.txt  merko ehitus interim report merko ehitus group..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns_adj = pd.DataFrame(data_clean.text.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaspere</th>\n",
       "      <th>able</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>accumulated</th>\n",
       "      <th>activeness</th>\n",
       "      <th>added</th>\n",
       "      <th>adjustment</th>\n",
       "      <th>adoption</th>\n",
       "      <th>advantage</th>\n",
       "      <th>aggressive</th>\n",
       "      <th>...</th>\n",
       "      <th>weakness</th>\n",
       "      <th>willing</th>\n",
       "      <th>willingness</th>\n",
       "      <th>wind</th>\n",
       "      <th>withdrawals</th>\n",
       "      <th>world</th>\n",
       "      <th>worse</th>\n",
       "      <th>worthiness</th>\n",
       "      <th>üksnurme</th>\n",
       "      <th>ādaži</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>merko2020_q1_en_eur_con_00.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q2_en_eur_con_00.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q3_en_eur_con_00.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merko2020_q4_en_eur_con_00.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 542 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                aaspere  able  accommodation  accumulated  \\\n",
       "merko2020_q1_en_eur_con_00.txt        2     0              1            0   \n",
       "merko2020_q2_en_eur_con_00.txt        2     2              0            0   \n",
       "merko2020_q3_en_eur_con_00.txt        2     1              0            1   \n",
       "merko2020_q4_en_eur_con_00.txt        0     1              0            1   \n",
       "\n",
       "                                activeness  added  adjustment  adoption  \\\n",
       "merko2020_q1_en_eur_con_00.txt           0      0           0         0   \n",
       "merko2020_q2_en_eur_con_00.txt           0      0           1         1   \n",
       "merko2020_q3_en_eur_con_00.txt           0      0           1         1   \n",
       "merko2020_q4_en_eur_con_00.txt           1      1           3         1   \n",
       "\n",
       "                                advantage  aggressive  ...  weakness  willing  \\\n",
       "merko2020_q1_en_eur_con_00.txt          0           1  ...         0        0   \n",
       "merko2020_q2_en_eur_con_00.txt          1           0  ...         1        1   \n",
       "merko2020_q3_en_eur_con_00.txt          0           0  ...         0        1   \n",
       "merko2020_q4_en_eur_con_00.txt          0           0  ...         0        0   \n",
       "\n",
       "                                willingness  wind  withdrawals  world  worse  \\\n",
       "merko2020_q1_en_eur_con_00.txt            0     0            0      1      0   \n",
       "merko2020_q2_en_eur_con_00.txt            0     2            0      3      1   \n",
       "merko2020_q3_en_eur_con_00.txt            1     2            0      1      0   \n",
       "merko2020_q4_en_eur_con_00.txt            1     2            1      0      0   \n",
       "\n",
       "                                worthiness  üksnurme  ādaži  \n",
       "merko2020_q1_en_eur_con_00.txt           0         1      0  \n",
       "merko2020_q2_en_eur_con_00.txt           1         1      0  \n",
       "merko2020_q3_en_eur_con_00.txt           0         0      2  \n",
       "merko2020_q4_en_eur_con_00.txt           0         0      4  \n",
       "\n",
       "[4 rows x 542 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.text)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.038*\"qtr\" + 0.013*\"reclassifications\" + 0.013*\"land\" + 0.010*\"methodology\" + 0.008*\"discount\" + 0.008*\"servitudes\" + 0.007*\"methods\" + 0.007*\"november\" + 0.007*\"sustainability\" + 0.006*\"coefficient\"'),\n",
       " (1,\n",
       "  '0.027*\"half\" + 0.013*\"gri\" + 0.011*\"women\" + 0.011*\"men\" + 0.010*\"ungc\" + 0.007*\"land\" + 0.007*\"reclassifications\" + 0.007*\"sasb\" + 0.007*\"sdg\" + 0.007*\"claim\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.041*\"qtr\" + 0.014*\"reclassifications\" + 0.014*\"land\" + 0.010*\"methodology\" + 0.008*\"servitudes\" + 0.008*\"discount\" + 0.008*\"methods\" + 0.008*\"november\" + 0.007*\"sustainability\" + 0.007*\"coefficient\"'),\n",
       " (1,\n",
       "  '0.028*\"half\" + 0.014*\"gri\" + 0.012*\"women\" + 0.011*\"men\" + 0.010*\"ungc\" + 0.008*\"sasb\" + 0.008*\"sdg\" + 0.007*\"land\" + 0.007*\"reclassifications\" + 0.007*\"claim\"'),\n",
       " (2,\n",
       "  '0.001*\"half\" + 0.001*\"land\" + 0.001*\"qtr\" + 0.001*\"reclassifications\" + 0.001*\"gri\" + 0.001*\"ungc\" + 0.001*\"men\" + 0.001*\"women\" + 0.001*\"sustainability\" + 0.001*\"esg\"')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 3 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.020*\"explanatory\" + 0.011*\"acquisitions\" + 0.011*\"corrections\" + 0.008*\"translation\" + 0.008*\"delays\" + 0.008*\"treatment\" + 0.006*\"condensed\" + 0.006*\"errors\" + 0.006*\"decline\" + 0.005*\"males\"'),\n",
       " (1,\n",
       "  '0.044*\"qtr\" + 0.015*\"reclassifications\" + 0.014*\"land\" + 0.011*\"methodology\" + 0.009*\"servitudes\" + 0.009*\"discount\" + 0.008*\"methods\" + 0.008*\"november\" + 0.008*\"sustainability\" + 0.007*\"subsequent\"'),\n",
       " (2,\n",
       "  '0.037*\"half\" + 0.014*\"land\" + 0.014*\"reclassifications\" + 0.013*\"gri\" + 0.011*\"women\" + 0.011*\"men\" + 0.010*\"methodology\" + 0.010*\"ungc\" + 0.010*\"captions\" + 0.009*\"table\"'),\n",
       " (3,\n",
       "  '0.023*\"half\" + 0.018*\"gri\" + 0.015*\"women\" + 0.014*\"men\" + 0.013*\"ungc\" + 0.013*\"condensed\" + 0.010*\"sdg\" + 0.010*\"sasb\" + 0.008*\"esg\" + 0.008*\"gj\"')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"course\" + 0.001*\"partnership\" + 0.001*\"allocated\" + 0.001*\"smooth\" + 0.001*\"announced\" + 0.001*\"seat\" + 0.001*\"certificates\" + 0.001*\"half\" + 0.001*\"care\" + 0.001*\"geographical\"'),\n",
       " (1,\n",
       "  '0.020*\"explanatory\" + 0.011*\"corrections\" + 0.011*\"acquisitions\" + 0.008*\"treatment\" + 0.008*\"delays\" + 0.008*\"translation\" + 0.006*\"errors\" + 0.006*\"condensed\" + 0.006*\"decline\" + 0.005*\"owners\"'),\n",
       " (2,\n",
       "  '0.044*\"qtr\" + 0.015*\"reclassifications\" + 0.014*\"land\" + 0.011*\"methodology\" + 0.009*\"servitudes\" + 0.009*\"discount\" + 0.008*\"november\" + 0.008*\"methods\" + 0.008*\"sustainability\" + 0.007*\"calculation\"'),\n",
       " (3,\n",
       "  '0.034*\"half\" + 0.017*\"gri\" + 0.014*\"women\" + 0.013*\"men\" + 0.012*\"ungc\" + 0.009*\"sdg\" + 0.009*\"sasb\" + 0.009*\"land\" + 0.009*\"reclassifications\" + 0.008*\"claim\"')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'ignitis2020_q1_en_eur_con_ias.txt'),\n",
       " (3, 'ignitis2020_q2_en_eur_con_ias.txt'),\n",
       " (3, 'ignitis2020_q2_en_eur_con_ias_00.txt'),\n",
       " (2, 'ignitis2020_q3_en_eur_con_ias.txt')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
