{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sõnade arvutamine\n",
    "\n",
    "Võtan tekstidest kõik sõnad ja võrdlen neid etteantud sõnadega, mis on seotud ESG'ga. Defineeritud sõnapaketi võtsin internetist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q1_16_eng.txt</th>\n",
       "      <td>delårsrapport för swedbank swedbank as estonia...</td>\n",
       "      <td>Q1_16_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1_17_eng.txt</th>\n",
       "      <td>delårsrapport för swedbank swedbank as estonia...</td>\n",
       "      <td>Q1_17_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1_18_eng.txt</th>\n",
       "      <td>delårsrapport för swedbank swedbank as estonia...</td>\n",
       "      <td>Q1_18_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1_19_eng.txt</th>\n",
       "      <td>swedbank as swedbank as i interim report janua...</td>\n",
       "      <td>Q1_19_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1_20_eng.txt</th>\n",
       "      <td>interim report january march swedbank as swedb...</td>\n",
       "      <td>Q1_20_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2_16_eng.txt</th>\n",
       "      <td>delårsrapport för swedbank swedbank as estonia...</td>\n",
       "      <td>Q2_16_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2_17_eng.txt</th>\n",
       "      <td>delårsrapport för swedbank swedbank as estonia...</td>\n",
       "      <td>Q2_17_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2_18_eng.txt</th>\n",
       "      <td>interim report january june swedbank as swedba...</td>\n",
       "      <td>Q2_18_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2_19_eng.txt</th>\n",
       "      <td>interim report january june swedbank as swedba...</td>\n",
       "      <td>Q2_19_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2_20_eng.txt</th>\n",
       "      <td>interim report january june swedbank as swedba...</td>\n",
       "      <td>Q2_20_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3_16_eng.txt</th>\n",
       "      <td>delårsrapport för swedbank swedbank as estonia...</td>\n",
       "      <td>Q3_16_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3_17_eng.txt</th>\n",
       "      <td>delårsrapport för swedbank swedbank as estonia...</td>\n",
       "      <td>Q3_17_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3_18_eng.txt</th>\n",
       "      <td>interim report january september swedbank as s...</td>\n",
       "      <td>Q3_18_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3_19_eng.txt</th>\n",
       "      <td>interim report january september swedbank as s...</td>\n",
       "      <td>Q3_19_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3_20_eng.txt</th>\n",
       "      <td>interim report january september swedbank as s...</td>\n",
       "      <td>Q3_20_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4_16_eng.txt</th>\n",
       "      <td>delårsrapport för swedbank swedbank as estonia...</td>\n",
       "      <td>Q4_16_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4_17_eng.txt</th>\n",
       "      <td>delårsrapport för swedbank swedbank as estonia...</td>\n",
       "      <td>Q4_17_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4_18_eng.txt</th>\n",
       "      <td>interim report january december swedbank as sw...</td>\n",
       "      <td>Q4_18_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4_19_eng.txt</th>\n",
       "      <td>interim report january december swedbank as sw...</td>\n",
       "      <td>Q4_19_eng.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4_20_eng.txt</th>\n",
       "      <td>interim report january december swedbank as sw...</td>\n",
       "      <td>Q4_20_eng.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            text  \\\n",
       "Q1_16_eng.txt  delårsrapport för swedbank swedbank as estonia...   \n",
       "Q1_17_eng.txt  delårsrapport för swedbank swedbank as estonia...   \n",
       "Q1_18_eng.txt  delårsrapport för swedbank swedbank as estonia...   \n",
       "Q1_19_eng.txt  swedbank as swedbank as i interim report janua...   \n",
       "Q1_20_eng.txt  interim report january march swedbank as swedb...   \n",
       "Q2_16_eng.txt  delårsrapport för swedbank swedbank as estonia...   \n",
       "Q2_17_eng.txt  delårsrapport för swedbank swedbank as estonia...   \n",
       "Q2_18_eng.txt  interim report january june swedbank as swedba...   \n",
       "Q2_19_eng.txt  interim report january june swedbank as swedba...   \n",
       "Q2_20_eng.txt  interim report january june swedbank as swedba...   \n",
       "Q3_16_eng.txt  delårsrapport för swedbank swedbank as estonia...   \n",
       "Q3_17_eng.txt  delårsrapport för swedbank swedbank as estonia...   \n",
       "Q3_18_eng.txt  interim report january september swedbank as s...   \n",
       "Q3_19_eng.txt  interim report january september swedbank as s...   \n",
       "Q3_20_eng.txt  interim report january september swedbank as s...   \n",
       "Q4_16_eng.txt  delårsrapport för swedbank swedbank as estonia...   \n",
       "Q4_17_eng.txt  delårsrapport för swedbank swedbank as estonia...   \n",
       "Q4_18_eng.txt  interim report january december swedbank as sw...   \n",
       "Q4_19_eng.txt  interim report january december swedbank as sw...   \n",
       "Q4_20_eng.txt  interim report january december swedbank as sw...   \n",
       "\n",
       "                    document  \n",
       "Q1_16_eng.txt  Q1_16_eng.txt  \n",
       "Q1_17_eng.txt  Q1_17_eng.txt  \n",
       "Q1_18_eng.txt  Q1_18_eng.txt  \n",
       "Q1_19_eng.txt  Q1_19_eng.txt  \n",
       "Q1_20_eng.txt  Q1_20_eng.txt  \n",
       "Q2_16_eng.txt  Q2_16_eng.txt  \n",
       "Q2_17_eng.txt  Q2_17_eng.txt  \n",
       "Q2_18_eng.txt  Q2_18_eng.txt  \n",
       "Q2_19_eng.txt  Q2_19_eng.txt  \n",
       "Q2_20_eng.txt  Q2_20_eng.txt  \n",
       "Q3_16_eng.txt  Q3_16_eng.txt  \n",
       "Q3_17_eng.txt  Q3_17_eng.txt  \n",
       "Q3_18_eng.txt  Q3_18_eng.txt  \n",
       "Q3_19_eng.txt  Q3_19_eng.txt  \n",
       "Q3_20_eng.txt  Q3_20_eng.txt  \n",
       "Q4_16_eng.txt  Q4_16_eng.txt  \n",
       "Q4_17_eng.txt  Q4_17_eng.txt  \n",
       "Q4_18_eng.txt  Q4_18_eng.txt  \n",
       "Q4_19_eng.txt  Q4_19_eng.txt  \n",
       "Q4_20_eng.txt  Q4_20_eng.txt  "
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "datacorp = pd.read_pickle('pickles/swed2016t2020.pkl')\n",
    "datacorp['document'] = datacorp.index\n",
    "\n",
    "query_G = 'Audit and control, Board structure, Remuneration, Shareholder rights, Transparency and Performance'\n",
    "query_S = 'Access to medicines, HIV, AIDs, Nutrition, Product safety, Community relations, Privacy and free expression, Security, Weak, governance zones, Diversity, Health and safety, ILO core conventions, Supply chain labor standards, Bribery and corruption, Political influence, Responsible marketing, Whistle-blowing systems, disclosure and reporting, Governance of sustainability issues, Stakeholder engagement, UNGC compliance'\n",
    "query_E = 'Biofuels, Climate ,Emissions ,land, Biodiversity, Water, Environmental, standards, Pollution, Supply, Waste, recycling'\n",
    "datacorp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from re import sub\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from gensim.similarities import SoftCosineSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# logimine\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.WARNING)  # DEBUG # INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marek.keskull\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1003,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# stoppsõnad\n",
    "nltk.download('stopwords') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 documents\n"
     ]
    }
   ],
   "source": [
    "#andmetest võtan andmepealkirjad ja tekstid nimetan dokumentideks\n",
    "\n",
    "titles = [item for item in datacorp['document']]\n",
    "documents = [item for item in datacorp['text']]\n",
    "\n",
    "\n",
    "print(f'{len(documents)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    doc = doc.lower().split()\n",
    "    stop_words = stopwords.words('english')\n",
    "    doc = [w for w in doc if w not in stop_words]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string\n",
    "def preprocess_query(doc):\n",
    "    doc = doc.lower().split()\n",
    "    doc = [remove_punc(i) for i in doc]\n",
    "    stop_words = stopwords.words('english')\n",
    "    doc = [w for w in doc if w not in stop_words]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(string):\n",
    "    punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
    "    for ele in string:  \n",
    "        if ele in punc:  \n",
    "            string = string.replace(ele, \"\") \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biofuels',\n",
       " 'climate',\n",
       " 'emissions',\n",
       " 'land',\n",
       " 'biodiversity',\n",
       " 'water',\n",
       " 'environmental',\n",
       " 'standards',\n",
       " 'pollution',\n",
       " 'supply',\n",
       " 'waste',\n",
       " 'recycling']"
      ]
     },
     "execution_count": 1075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [preprocess(document) for document in documents]\n",
    "\n",
    "query = preprocess_query(query_E)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#pre-trained embeddings\n",
    "# glove vektoripakk, siin on 400000 vektorit sees \n",
    "#https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "if 'glove' not in locals():  \n",
    "    glove = api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "#print(glove.most_similar(\"remuneration\"))\n",
    "\n",
    "#A term similarity index that computes cosine similarities between word embeddings.\n",
    "#1) Compute cosine similarities between word embeddings.\n",
    "#2) Retrieve the closest word embeddings (by cosine similarity) to a given word embedding.\n",
    "\n",
    "similarity_index = WordEmbeddingSimilarityIndex(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(corpus+[query])\n",
    "print(dictionary.get(8099))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liability\n"
     ]
    }
   ],
   "source": [
    "#ehitame TF-idf mudeli\n",
    "    \n",
    "#kõigepealt ehitame valmis andmesõnastiku, kus on sees kõik dokumendi sõnad ja otsingupäringu sõnad vormis: 'võti':'sõna'\n",
    "dictionary = Dictionary(corpus+[query])\n",
    "print(dictionary.get(455))\n",
    "\n",
    "#This module implements functionality related to the \n",
    "#Term Frequency - Inverse Document Frequency vector space bag-of-words models.\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "    \n",
    "    \n",
    "#Builds a sparse term similarity matrix using a term similarity index. \n",
    "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf, nonzero_limit=100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(469, 1), (470, 1), (471, 1), (472, 1), (473, 1), (474, 1), (475, 1), (476, 1), (477, 1), (478, 1), (479, 1), (480, 1)]\n",
      "\n",
      "[(469, 0.28867513459481287), (470, 0.28867513459481287), (471, 0.28867513459481287), (472, 0.28867513459481287), (473, 0.28867513459481287), (474, 0.28867513459481287), (475, 0.28867513459481287), (476, 0.28867513459481287), (477, 0.28867513459481287), (478, 0.28867513459481287), (479, 0.28867513459481287), (480, 0.28867513459481287)]\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(corpus+[query])\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "print(dictionary.doc2bow(query))\n",
    "print()\n",
    "print(tfidf.__getitem__(dictionary.doc2bow(query),eps=0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(469, 0.28867513459481287), (470, 0.28867513459481287), (471, 0.28867513459481287), (472, 0.28867513459481287), (473, 0.28867513459481287), (474, 0.28867513459481287), (475, 0.28867513459481287), (476, 0.28867513459481287), (477, 0.28867513459481287), (478, 0.28867513459481287), (479, 0.28867513459481287), (480, 0.28867513459481287)]\n",
      "[0.27431798 0.17771125 0.28758943 0.287723   0.28371674 0.2805964\n",
      " 0.2858753  0.27897158 0.29564533 0.28451794 0.2805964  0.2858753\n",
      " 0.27897155 0.29564533 0.28451794 0.2858753  0.28918618 0.2918557\n",
      " 0.28451797 0.28451797]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query_tf = tfidf[dictionary.doc2bow(query)]\n",
    "print(query_tf)\n",
    "\n",
    "#Compute soft cosine similarity against a corpus of documents by storing the index matrix in memory.\n",
    "index = SoftCosineSimilarity(tfidf[[dictionary.doc2bow(document) for document in corpus]],similarity_matrix)\n",
    "\n",
    "doc_similarity_scores = index[query_tf]\n",
    "print(doc_similarity_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \t 0.295645 \t Q2_19_eng.txt\n",
      "13 \t 0.295645 \t Q3_19_eng.txt\n",
      "17 \t 0.291856 \t Q4_18_eng.txt\n",
      "16 \t 0.289186 \t Q4_17_eng.txt\n",
      "3 \t 0.287723 \t Q1_19_eng.txt\n",
      "2 \t 0.287589 \t Q1_18_eng.txt\n",
      "15 \t 0.285875 \t Q4_16_eng.txt\n",
      "11 \t 0.285875 \t Q3_17_eng.txt\n",
      "6 \t 0.285875 \t Q2_17_eng.txt\n",
      "19 \t 0.284518 \t Q4_20_eng.txt\n",
      "18 \t 0.284518 \t Q4_19_eng.txt\n",
      "9 \t 0.284518 \t Q2_20_eng.txt\n",
      "14 \t 0.284518 \t Q3_20_eng.txt\n",
      "4 \t 0.283717 \t Q1_20_eng.txt\n",
      "10 \t 0.280596 \t Q3_16_eng.txt\n",
      "5 \t 0.280596 \t Q2_16_eng.txt\n",
      "7 \t 0.278972 \t Q2_18_eng.txt\n",
      "12 \t 0.278972 \t Q3_18_eng.txt\n",
      "0 \t 0.274318 \t Q1_16_eng.txt\n",
      "1 \t 0.177711 \t Q1_17_eng.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sorted_indexes = np.argsort(doc_similarity_scores)[::-1]\n",
    "for idx in sorted_indexes[:30]:\n",
    "    print(f'{idx} \\t {doc_similarity_scores[idx]:0.6f} \\t {titles[idx]}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_similar_terms = []\n",
    "max_results_per_doc = 30\n",
    "#query = ['audit', 'control', 'board', 'structure', 'remuneration', 'shareholder', 'rights', 'transparency', 'performance']\n",
    "for term in query:\n",
    "    #dictionary = Dictionary(corpus+[query])\n",
    "    #dictionary is query + my corpus(which has 25 documents)\n",
    "\n",
    "    idx1 = dictionary.token2id[term]\n",
    "    for document in corpus:\n",
    "        #print(document.name)\n",
    "        results_this_doc = []\n",
    "        for word in set(document):\n",
    "            idx2 = dictionary.token2id[word]\n",
    "            score = similarity_matrix.matrix[idx1, idx2]\n",
    "            if score > 0.0:\n",
    "                results_this_doc.append((word, score))\n",
    "               \n",
    "        results_this_doc = sorted(results_this_doc, reverse=True, key=lambda x: x[1])\n",
    "        \n",
    "        results_this_doc = results_this_doc[:min(len(results_this_doc), max_results_per_doc)]\n",
    "        #print(results_this_doc)\n",
    "        doc_similar_terms.append(results_this_doc)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \t 0.296 \t Q2_19_eng.txt  :  \n",
      "13 \t 0.296 \t Q3_19_eng.txt  :  \n",
      "17 \t 0.292 \t Q4_18_eng.txt  :  \n",
      "16 \t 0.289 \t Q4_17_eng.txt  :  \n",
      "3 \t 0.288 \t Q1_19_eng.txt  :  \n",
      "2 \t 0.288 \t Q1_18_eng.txt  :  \n",
      "15 \t 0.286 \t Q4_16_eng.txt  :  \n",
      "11 \t 0.286 \t Q3_17_eng.txt  :  \n",
      "6 \t 0.286 \t Q2_17_eng.txt  :  \n",
      "19 \t 0.285 \t Q4_20_eng.txt  :  \n",
      "18 \t 0.285 \t Q4_19_eng.txt  :  \n",
      "9 \t 0.285 \t Q2_20_eng.txt  :  \n",
      "14 \t 0.285 \t Q3_20_eng.txt  :  \n",
      "4 \t 0.284 \t Q1_20_eng.txt  :  \n",
      "10 \t 0.281 \t Q3_16_eng.txt  :  \n",
      "5 \t 0.281 \t Q2_16_eng.txt  :  \n",
      "7 \t 0.279 \t Q2_18_eng.txt  :  \n",
      "12 \t 0.279 \t Q3_18_eng.txt  :  \n",
      "0 \t 0.274 \t Q1_16_eng.txt  :  \n",
      "1 \t 0.178 \t Q1_17_eng.txt  :  \n"
     ]
    }
   ],
   "source": [
    "#esimese 15 dokumendi tulemused koos sarnaste sõnadega\n",
    "results = []\n",
    "for idx in sorted_indexes[:30]:\n",
    "    \n",
    "    similar_terms_string = ', '.join([result[0] for result in doc_similar_terms[idx]])\n",
    "    \n",
    "    results.append([idx,doc_similarity_scores[idx],titles[idx],similar_terms_string])\n",
    "    print(f'{idx} \\t {doc_similarity_scores[idx]:0.3f} \\t {titles[idx]}  :  {similar_terms_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=[\"Index of document\", \"Similarity score in environment topic\",\"Document name\",\"Most similar words in environment topic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index of document</th>\n",
       "      <th>Similarity score in environment topic</th>\n",
       "      <th>Document name</th>\n",
       "      <th>Most similar words in environment topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.295645</td>\n",
       "      <td>Q2_19_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.295645</td>\n",
       "      <td>Q3_19_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0.291856</td>\n",
       "      <td>Q4_18_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.289186</td>\n",
       "      <td>Q4_17_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.287723</td>\n",
       "      <td>Q1_19_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.287589</td>\n",
       "      <td>Q1_18_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>0.285875</td>\n",
       "      <td>Q4_16_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>0.285875</td>\n",
       "      <td>Q3_17_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>0.285875</td>\n",
       "      <td>Q2_17_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.284518</td>\n",
       "      <td>Q4_20_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>0.284518</td>\n",
       "      <td>Q4_19_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>0.284518</td>\n",
       "      <td>Q2_20_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.284518</td>\n",
       "      <td>Q3_20_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0.283717</td>\n",
       "      <td>Q1_20_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>0.280596</td>\n",
       "      <td>Q3_16_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>0.280596</td>\n",
       "      <td>Q2_16_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>0.278972</td>\n",
       "      <td>Q2_18_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12</td>\n",
       "      <td>0.278972</td>\n",
       "      <td>Q3_18_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.274318</td>\n",
       "      <td>Q1_16_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.177711</td>\n",
       "      <td>Q1_17_eng.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index of document  Similarity score in environment topic  Document name  \\\n",
       "0                   8                               0.295645  Q2_19_eng.txt   \n",
       "1                  13                               0.295645  Q3_19_eng.txt   \n",
       "2                  17                               0.291856  Q4_18_eng.txt   \n",
       "3                  16                               0.289186  Q4_17_eng.txt   \n",
       "4                   3                               0.287723  Q1_19_eng.txt   \n",
       "5                   2                               0.287589  Q1_18_eng.txt   \n",
       "6                  15                               0.285875  Q4_16_eng.txt   \n",
       "7                  11                               0.285875  Q3_17_eng.txt   \n",
       "8                   6                               0.285875  Q2_17_eng.txt   \n",
       "9                  19                               0.284518  Q4_20_eng.txt   \n",
       "10                 18                               0.284518  Q4_19_eng.txt   \n",
       "11                  9                               0.284518  Q2_20_eng.txt   \n",
       "12                 14                               0.284518  Q3_20_eng.txt   \n",
       "13                  4                               0.283717  Q1_20_eng.txt   \n",
       "14                 10                               0.280596  Q3_16_eng.txt   \n",
       "15                  5                               0.280596  Q2_16_eng.txt   \n",
       "16                  7                               0.278972  Q2_18_eng.txt   \n",
       "17                 12                               0.278972  Q3_18_eng.txt   \n",
       "18                  0                               0.274318  Q1_16_eng.txt   \n",
       "19                  1                               0.177711  Q1_17_eng.txt   \n",
       "\n",
       "   Most similar words in environment topic  \n",
       "0                                           \n",
       "1                                           \n",
       "2                                           \n",
       "3                                           \n",
       "4                                           \n",
       "5                                           \n",
       "6                                           \n",
       "7                                           \n",
       "8                                           \n",
       "9                                           \n",
       "10                                          \n",
       "11                                          \n",
       "12                                          \n",
       "13                                          \n",
       "14                                          \n",
       "15                                          \n",
       "16                                          \n",
       "17                                          \n",
       "18                                          \n",
       "19                                          "
      ]
     },
     "execution_count": 1085,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "df.to_pickle('Environmentresults/Swedbank.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order of similarity</th>\n",
       "      <th>Similarity score</th>\n",
       "      <th>Document name</th>\n",
       "      <th>Most similar words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.264879</td>\n",
       "      <td>swedbankQ2_20_eng.txt</td>\n",
       "      <td>critical, fax, bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.267326</td>\n",
       "      <td>swedbankQ3_20_eng.txt</td>\n",
       "      <td>critical, fax, bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order of similarity  Similarity score          Document name  \\\n",
       "0                    1          0.264879  swedbankQ2_20_eng.txt   \n",
       "1                    2          0.267326  swedbankQ3_20_eng.txt   \n",
       "\n",
       "    Most similar words  \n",
       "0  critical, fax, bank  \n",
       "1  critical, fax, bank  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacorpswed = pd.read_pickle('resultdata/swedsimilarityscores.pkl')\n",
    "datacorpswed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order of similarity</th>\n",
       "      <th>Similarity score</th>\n",
       "      <th>Document name</th>\n",
       "      <th>Most similar words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.261196</td>\n",
       "      <td>lhv2020_q1_en_eur_con_00.txt</td>\n",
       "      <td>note, collection, operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.040926</td>\n",
       "      <td>lhv2020_q2_en_eur_00_00.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.267063</td>\n",
       "      <td>lhv2020_q2_en_eur_con_00.txt</td>\n",
       "      <td>note, collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.040926</td>\n",
       "      <td>lhv2020_q1_en_eur_00_00.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order of similarity  Similarity score                 Document name  \\\n",
       "0                    1          0.261196  lhv2020_q1_en_eur_con_00.txt   \n",
       "1                    2          0.040926   lhv2020_q2_en_eur_00_00.txt   \n",
       "2                    3          0.267063  lhv2020_q2_en_eur_con_00.txt   \n",
       "3                    0          0.040926   lhv2020_q1_en_eur_00_00.txt   \n",
       "\n",
       "            Most similar words  \n",
       "0  note, collection, operation  \n",
       "1                               \n",
       "2             note, collection  \n",
       "3                               "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacorplhv = pd.read_pickle('resultdata/lhvsimilarityscores.pkl')\n",
    "datacorplhv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index of document</th>\n",
       "      <th>Similarity score</th>\n",
       "      <th>Document name</th>\n",
       "      <th>Most similar words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.431862</td>\n",
       "      <td>lhv_annual_2019.txt</td>\n",
       "      <td>biodiversity, conservation, ecological, sustai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.486714</td>\n",
       "      <td>seb_annual_report_2019.txt</td>\n",
       "      <td>ecosystem, conservation, ecosystems, sustainab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.518059</td>\n",
       "      <td>swedannual2019.txt</td>\n",
       "      <td>conservation, sustainable, sustainability, div...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.461859</td>\n",
       "      <td>annual_report_2019_luminor.txt</td>\n",
       "      <td>ecological, sustainable, sustainability, diver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index of document  Similarity score                   Document name  \\\n",
       "0                  1          0.431862             lhv_annual_2019.txt   \n",
       "1                  2          0.486714      seb_annual_report_2019.txt   \n",
       "2                  3          0.518059              swedannual2019.txt   \n",
       "3                  0          0.461859  annual_report_2019_luminor.txt   \n",
       "\n",
       "                                  Most similar words  \n",
       "0  biodiversity, conservation, ecological, sustai...  \n",
       "1  ecosystem, conservation, ecosystems, sustainab...  \n",
       "2  conservation, sustainable, sustainability, div...  \n",
       "3  ecological, sustainable, sustainability, diver...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "databank = pd.read_pickle('annualresults/2019banksimilarityscores.pkl')\n",
    "databank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valideerimine näiteks balti pankade uuring: https://www.estwatch.ee/wp-content/uploads/2020/02/Vastutustundlikkus-Eesti-panganduses-Estwatch.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docsim import DocSim\n",
    "import docsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default GloVe word vector model: glove-wiki-gigaword-50\n",
      "Model loaded\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "docsim_obj = docsim.DocSim(verbose=True)\n",
    "# docsim_obj = docsim.DocSim_threaded(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready: True\n"
     ]
    }
   ],
   "source": [
    "print(f'Model ready: {docsim_obj.model_ready}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 documents\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles = [item for item in datacorp['document']]\n",
    "documents = [item for item in datacorp['text']]\n",
    "\n",
    "print(f'{len(documents)} documents')\n",
    "\n",
    "query_string = 'Audit and control, Board structure, Remuneration, Shareholder rights, Transparency and Performance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 documents loaded into corpus\n",
      "Wall time: 36.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marek.keskull\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\termsim.py:358: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  Y = np.multiply(Y, 1 / np.sqrt(Y_norm))\n",
      "C:\\Users\\marek.keskull\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\termsim.py:358: RuntimeWarning: invalid value encountered in multiply\n",
      "  Y = np.multiply(Y, 1 / np.sqrt(Y_norm))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "similarities = docsim_obj.similarity_query(query_string, documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \t 0.547 \t lhv2020_q2_en_eur_con_00.txt\n",
      "5 \t 0.535 \t lhv2020_q3_en_eur_con_00.txt\n",
      "1 \t 0.524 \t lhv2020_q1_en_eur_con_00.txt\n",
      "4 \t 0.355 \t lhv2020_q3_en_eur_00_00.txt\n",
      "0 \t 0.000 \t lhv2020_q1_en_eur_00_00.txt\n",
      "2 \t 0.000 \t lhv2020_q2_en_eur_00_00.txt\n"
     ]
    }
   ],
   "source": [
    "for idx, score in (sorted(enumerate(similarities), reverse=True, key=lambda x: x[1])[:15]):\n",
    "    print(f'{idx} \\t {score:0.3f} \\t {titles[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.5235986709594727, 0.0, 0.5465497970581055, 0.3552752733230591, 0.5345579385757446]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
