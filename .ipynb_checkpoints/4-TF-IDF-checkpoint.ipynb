{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sõnade arvutamine\n",
    "\n",
    "Võtan tekstidest kõik sõnad ja võrdlen neid etteantud sõnadega, mis on seotud ESG'ga. Defineeritud sõnapaketi võtsin internetist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>quarters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ignitis2020_q1_en_eur_con_ias.txt</th>\n",
       "      <td>interim report consolidated interim report for...</td>\n",
       "      <td>[interim, report, consolidated, interim, repor...</td>\n",
       "      <td>ignitis2020_q1_en_eur_con_ias.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignitis2020_q2_en_eur_con_ias.txt</th>\n",
       "      <td>interim report consolidated interim report for...</td>\n",
       "      <td>[interim, report, consolidated, interim, repor...</td>\n",
       "      <td>ignitis2020_q2_en_eur_con_ias.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignitis2020_q2_en_eur_con_ias_00.txt</th>\n",
       "      <td>interim report consolidated interim report for...</td>\n",
       "      <td>[interim, report, consolidated, interim, repor...</td>\n",
       "      <td>ignitis2020_q2_en_eur_con_ias_00.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignitis2020_q3_en_eur_con_ias.txt</th>\n",
       "      <td>interim report first nine months consolidated ...</td>\n",
       "      <td>[interim, report, first, nine, months, consoli...</td>\n",
       "      <td>ignitis2020_q3_en_eur_con_ias.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                   text  \\\n",
       "ignitis2020_q1_en_eur_con_ias.txt     interim report consolidated interim report for...   \n",
       "ignitis2020_q2_en_eur_con_ias.txt     interim report consolidated interim report for...   \n",
       "ignitis2020_q2_en_eur_con_ias_00.txt  interim report consolidated interim report for...   \n",
       "ignitis2020_q3_en_eur_con_ias.txt     interim report first nine months consolidated ...   \n",
       "\n",
       "                                                                               unigrams  \\\n",
       "ignitis2020_q1_en_eur_con_ias.txt     [interim, report, consolidated, interim, repor...   \n",
       "ignitis2020_q2_en_eur_con_ias.txt     [interim, report, consolidated, interim, repor...   \n",
       "ignitis2020_q2_en_eur_con_ias_00.txt  [interim, report, consolidated, interim, repor...   \n",
       "ignitis2020_q3_en_eur_con_ias.txt     [interim, report, first, nine, months, consoli...   \n",
       "\n",
       "                                                                  quarters  \n",
       "ignitis2020_q1_en_eur_con_ias.txt        ignitis2020_q1_en_eur_con_ias.txt  \n",
       "ignitis2020_q2_en_eur_con_ias.txt        ignitis2020_q2_en_eur_con_ias.txt  \n",
       "ignitis2020_q2_en_eur_con_ias_00.txt  ignitis2020_q2_en_eur_con_ias_00.txt  \n",
       "ignitis2020_q3_en_eur_con_ias.txt        ignitis2020_q3_en_eur_con_ias.txt  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "datacorp = pd.read_pickle('pickles/corpus.pkl')\n",
    "datacorp[\"unigrams\"] = datacorp[\"text\"].apply(nltk.word_tokenize)\n",
    "datacorp['quarters'] = datacorp.index\n",
    "datacorp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from re import sub\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from gensim.similarities import SoftCosineSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# logimine\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.WARNING)  # DEBUG # INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marek.keskull\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# stoppsõnad\n",
    "nltk.download('stopwords') \n",
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#andmetest võtan andmepealkirjad ja tekstid nimetan dokumentideks\n",
    "\n",
    "titles = [item for item in datacorp['quarters']]\n",
    "documents = [item for item in datacorp['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    # puhastamine ja tokeniseerimine\n",
    "    doc = sub(r'<img[^<>]+(>|$)', \" image_token \", doc)\n",
    "    doc = sub(r'<[^<>]+(>|$)', \" \", doc)\n",
    "    doc = sub(r'\\[img_assist[^]]*?\\]', \" \", doc)\n",
    "    doc = sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', \" url_token \", doc)\n",
    "    return [token for token in simple_preprocess(doc, min_len=0, max_len=float(\"inf\")) if token not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_string = 'biodiversity'\n",
    "query_Environment = 'Biodiversity Carbon Cleantech Clean Climate Coal Conservation Ecosystem Emission Energy Fuel Green Land Natural Pollution Renewable Resources Sustainability Sustainable Toxic Waste Water Accident Alcohol Anti-personnel Behavior Charity Community Controversial Controversy Discrimination Gambling Health Human capital Human rights Inclusion Injury Lab Munitions Opposition Pay Philanthropic Quality Responsible Advocacy Bribery Compensation Competitive Corruption Divestment Fraud GRI Independent Justice Stability Stewardship Transparency'\n",
    "query_Social = 'Accident Alcohol Anti-personnel Behavior Charity Community Controversial Controversy Discrimination Gambling Health Human capital Human rights Inclusion Injury Lab Munitions Opposition Pay Philanthropic Quality Responsible'\n",
    "query_Government = 'Advocacy Bribery Compensation Competitive Corruption Divestment Fraud GRI Independent Justice Stability Stewardship Transparency'\n",
    "\n",
    "\n",
    "# Preprocess meetod\n",
    "corpus = [preprocess(document) for document in documents]\n",
    "query = preprocess(query_Environment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# glove vektoripakk, siin on 400000 vektorit sees \n",
    "#https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "if 'glove' not in locals():  \n",
    "    glove = api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "\n",
    "#arvutame välja koosinuse sarnasused välja sõnavektorides\n",
    "similarity_index = WordEmbeddingSimilarityIndex(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ehitame TF-idf mudeli\n",
    "def build_term(corpus, query):\n",
    "    # The search query must be in the dictionary as well, in case the terms do not overlap with the documents (we still want similarity)\n",
    "    dictionary = Dictionary(corpus+[query])\n",
    "    tfidf = TfidfModel(dictionary=dictionary)\n",
    "    # Create the term similarity matrix. \n",
    "    # The nonzero_limit enforces sparsity by limiting the number of non-zero terms in each column. \n",
    "    similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf)  # , nonzero_limit=None)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = build_term(corpus, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_similarity_scores(query,similarity_matrix):\n",
    "    dictionary = Dictionary(corpus+[query])\n",
    "    tfidf = TfidfModel(dictionary=dictionary)\n",
    "    query_tf = tfidf[dictionary.doc2bow(query)]\n",
    "    index = SoftCosineSimilarity(tfidf[[dictionary.doc2bow(document) for document in corpus]],similarity_matrix)\n",
    "    doc_similarity_scores = index[query_tf]\n",
    "    return doc_similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "document_sim_scores = doc_similarity_scores(query,tfidf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meetod sarnasusskooride sortimiseks\n",
    "def sort_similarity_scores_by_document(doc_similarity_scores):\n",
    "    sorted_indexes = np.argsort(doc_similarity_scores)[::-1]\n",
    "    #for idx in sorted_indexes[:15]:\n",
    "        #print(f'{idx} \\t {doc_similarity_scores[idx]:0.3f} \\t {titles[idx]}')\n",
    "        \n",
    "    return sorted_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sim_scores = sort_similarity_scores_by_document(document_sim_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_similar_terms = []\n",
    "max_results_per_doc = 30\n",
    "for term in query:\n",
    "    dictionary = Dictionary(corpus+[query])\n",
    "    idx1 = dictionary.token2id[term]\n",
    "    for document in corpus:\n",
    "        results_this_doc = []\n",
    "        for word in set(document):\n",
    "            idx2 = dictionary.token2id[word]\n",
    "            score = a.matrix[idx1, idx2]\n",
    "            if score > 0.0:\n",
    "                results_this_doc.append((word, score))\n",
    "        results_this_doc = sorted(results_this_doc, reverse=True, key=lambda x: x[1])  # sort results by score\n",
    "        results_this_doc = results_this_doc[:min(len(results_this_doc), max_results_per_doc)]  # take the top results\n",
    "        doc_similar_terms.append(results_this_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t 0.440 \t ignitis2020_q2_en_eur_con_ias.txt\n",
      "2 \t 0.408 \t ignitis2020_q2_en_eur_con_ias_00.txt\n",
      "3 \t 0.408 \t ignitis2020_q3_en_eur_con_ias.txt\n",
      "0 \t 0.382 \t ignitis2020_q1_en_eur_con_ias.txt\n"
     ]
    }
   ],
   "source": [
    "#esimese 15 dokumendi tulemused\n",
    "for idx in s[:15]:\n",
    "    similar_terms_string = ', '.join([result[0] for result in doc_similar_terms[idx]])\n",
    "    print(f'{idx} \\t {document_sim_scores[idx]:0.3f} \\t {titles[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t 0.440 \t ignitis2020_q2_en_eur_con_ias.txt  :  sustainable, sustainability, preservation, diversity, environmental, resource, climate, impacts, environment, resources, natural, development, mitigation, global, nature, impact, implications\n",
      "2 \t 0.408 \t ignitis2020_q2_en_eur_con_ias_00.txt  :  sustainable, sustainability, preservation, diversity, environmental, resource, climate, impacts, environment, resources, natural, preserving, development, mitigation, global, nature, impact, implications\n",
      "3 \t 0.408 \t ignitis2020_q3_en_eur_con_ias.txt  :  sustainable, sustainability, preservation, diversity, environmental, climate, impacts, environment, resources, oceans, natural, preserving, development, global, nature, impact, implications\n",
      "0 \t 0.382 \t ignitis2020_q1_en_eur_con_ias.txt  :  sustainable, diversity, environmental, resource, environment, resources, natural, preserving, development, awareness, global, nature, prevention, pollution, impact, implications\n"
     ]
    }
   ],
   "source": [
    "#esimese 15 dokumendi tulemused koos sarnaste sõnadega\n",
    "results = []\n",
    "for idx in s[:15]:\n",
    "    similar_terms_string = ', '.join([result[0] for result in doc_similar_terms[idx]])\n",
    "    results.append([idx,document_sim_scores[idx],titles[idx],similar_terms_string])\n",
    "    print(f'{idx} \\t {b[idx]:0.3f} \\t {titles[idx]}  :  {similar_terms_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=[\"Order of similarity\", \"Similarity score\",\"Document name\",\"Most similar words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order of similarity</th>\n",
       "      <th>Similarity score</th>\n",
       "      <th>Document name</th>\n",
       "      <th>Most similar words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.439973</td>\n",
       "      <td>ignitis2020_q2_en_eur_con_ias.txt</td>\n",
       "      <td>sustainable, sustainability, preservation, div...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.408070</td>\n",
       "      <td>ignitis2020_q2_en_eur_con_ias_00.txt</td>\n",
       "      <td>sustainable, sustainability, preservation, div...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.407780</td>\n",
       "      <td>ignitis2020_q3_en_eur_con_ias.txt</td>\n",
       "      <td>sustainable, sustainability, preservation, div...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.381633</td>\n",
       "      <td>ignitis2020_q1_en_eur_con_ias.txt</td>\n",
       "      <td>sustainable, diversity, environmental, resourc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order of similarity  Similarity score  \\\n",
       "0                    1          0.439973   \n",
       "1                    2          0.408070   \n",
       "2                    3          0.407780   \n",
       "3                    0          0.381633   \n",
       "\n",
       "                          Document name  \\\n",
       "0     ignitis2020_q2_en_eur_con_ias.txt   \n",
       "1  ignitis2020_q2_en_eur_con_ias_00.txt   \n",
       "2     ignitis2020_q3_en_eur_con_ias.txt   \n",
       "3     ignitis2020_q1_en_eur_con_ias.txt   \n",
       "\n",
       "                                  Most similar words  \n",
       "0  sustainable, sustainability, preservation, div...  \n",
       "1  sustainable, sustainability, preservation, div...  \n",
       "2  sustainable, sustainability, preservation, div...  \n",
       "3  sustainable, diversity, environmental, resourc...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "df.to_pickle('resultdata/ignitissimilarityscores.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
